{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851da068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import allel\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49de645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####GET ADJACENT WINDOW RESULTS FROM INFERENCE RESULTS. INPUT FILES ARE OUTPUTS FROM H12_table_for_ROC_snps.py AND\n",
    "#####SF_table_for_ROC_wins.py#####\n",
    "winSize=10000\n",
    "regionLen=997204\n",
    "#Set col names for categorising FPs, TPs etc (adjust for SweepFinder2 analysis)\n",
    "col1  = 'H12'\n",
    "col2 = 'sweep'\n",
    "choices = ['FN','TP','FP','TN']\n",
    "\n",
    "#Loop through 2Nes values\n",
    "for s in [100, 1000, 10000]:\n",
    "    #Create df to store all inference results\n",
    "    rdf = pd.DataFrame()\n",
    "    #list to store inferenc results\n",
    "    df_lst = []\n",
    "    #Loop through replicates\n",
    "    for i in range(1, 201):\n",
    "        try:\n",
    "            #Read in inference file and concatenate to rdf\n",
    "            df = pd.read_csv(inferenceFile, sep='\\t', header=0)\n",
    "            df.columns = [col2, col1]\n",
    "            rdf = pd.concat([rdf, df])\n",
    "            #Append df to list\n",
    "            df_lst.append(df)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    rdf = rdf.dropna()\n",
    "    #Calculate ROC statistics\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(rdf.sweep, rdf['H12'])\n",
    "\n",
    "    res = []\n",
    "    #Set number of thresholds for adjacent windows method using min and max thresholds from metrics.roc_curve function above\n",
    "    new_thresholds = np.linspace(np.min(thresholds), np.max(thresholds), 1000)\n",
    "    with open(outFile, 'a') as outfile:\n",
    "        #Loop through thresholds\n",
    "        for i, t in enumerate(new_thresholds):\n",
    "            rdf = pd.DataFrame()\n",
    "            TP = 0\n",
    "            TN = 0\n",
    "            FP = 0\n",
    "            FN = 0\n",
    "            #Loop through dfs (ie replicates)\n",
    "            for df in df_lst:\n",
    "                #Set conditions using thresholds and apply to column\n",
    "                conditions = [(df[col1]<t) & (df[col2]==1), \n",
    "                             (df[col1]>=t) & (df[col2]==1),\n",
    "                             (df[col1]>=t) & (df[col2]==0),\n",
    "                             (df[col1]<t) & (df[col2]==0)]\n",
    "\n",
    "                df['outcome'] = np.select(conditions, choices, default=np.nan)\n",
    "\n",
    "                lst = list(df.outcome)\n",
    "                #Set column which will be the final results column\n",
    "                df['final_outcome'] = df.outcome\n",
    "                #Set columns shifted one forward and back (ie adjacent windows)\n",
    "                df[\"next_outcome\"] = df.outcome.shift(-1) \n",
    "                df[\"prior_outcome\"] = df.outcome.shift(1)\n",
    "                #While loop keeps until there are no instances where a true positive is next to a false positive\n",
    "                while(len(df[(df.next_outcome.eq(\"TP\") & df.final_outcome.eq(\"FP\")) |\n",
    "                   (df.prior_outcome.eq(\"TP\") & df.final_outcome.eq(\"FP\"))]) > 0):\n",
    "                    #If the next window (either before or after) is a TP, set to TP\n",
    "                    df['final_outcome'] = np.where(df.next_outcome.eq(\"TP\") & df.outcome.eq(\"FP\") & (df[col1]>=t), \n",
    "                                                   'TP', df.final_outcome)\n",
    "                    df['final_outcome'] = np.where(df.prior_outcome.eq(\"TP\") & df.outcome.eq(\"FP\") & (df[col1]>=t), \n",
    "                                                   'TP', df.final_outcome)\n",
    "\n",
    "                rdf = pd.concat([rdf, df])\n",
    "            #Get the value counts for each category and output to file\n",
    "            if('TP' in rdf.final_outcome.value_counts()):\n",
    "                TP += rdf.final_outcome.value_counts()['TP']\n",
    "            if('FP' in rdf.final_outcome.value_counts()):\n",
    "                FP += rdf.final_outcome.value_counts()['FP']\n",
    "            if('TN' in rdf.final_outcome.value_counts()):\n",
    "                TN += rdf.final_outcome.value_counts()['TN']\n",
    "            if('FN' in rdf.final_outcome.value_counts()):\n",
    "                FN += rdf.final_outcome.value_counts()['FN']\n",
    "            res.append([TP,FP,TN,FN])\n",
    "            outfile.write('\\t'.join([str(x) for x in [t,TP,FP,TN,FN]]) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
