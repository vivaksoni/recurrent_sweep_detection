{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f698ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import allel\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaab21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####COMPARE POWER OF OUTLIER AND NULL THRESHOLD APPROACHES USING INFERENCE RESULTS (OUTPUTS FROM get_H12_snp.py AND SF2)\n",
    "#####AND FIXED FILE FROM SLIM OUTPUT.#####\n",
    "winSize=10000\n",
    "regionLen=997204\n",
    "#Set col names for categorising FPs, TPs etc (adjust for SweepFinder2 analysis)\n",
    "col1  = 'H12'\n",
    "col2 = 'sweep'\n",
    "#Create empty df for results\n",
    "rdf = pd.DataFrame()\n",
    "        \n",
    "####GET HIGHEST H12 VALUE FROM SIMULATIONS WITH NO SWEEPS####\n",
    "lst = []\n",
    "for rep in range(1,201):\n",
    "    try:\n",
    "        df = pd.read_csv(inferenceFile, sep='\\t', header=0)\n",
    "        #Get max value of current replicaate\n",
    "        lst.append(df['H12'].max())\n",
    "    except Exception:\n",
    "        pass\n",
    "#Get max value of all resplicates\n",
    "null_threshold = np.max(lst)\n",
    "\n",
    "#Create empty list to store results for each 2Nes value\n",
    "results = []\n",
    "#Loop through 2Nes values\n",
    "for N in ['noSweeps',100, 1000, 10000]:\n",
    "    #Empty lists to store TP, FP etc for each replicate\n",
    "    null = []\n",
    "    tail = []\n",
    "    #Loop through replicates\n",
    "    for rep in range(1,201):\n",
    "        #Read in inference results\n",
    "        res = pd.read_csv(inferenceFile, sep='\\t', header=0)\n",
    "\n",
    "\n",
    "        #Read in .fixed file\n",
    "        fixed = pd.read_csv(fixedFile, skiprows=2, sep=' ',\n",
    "                           names=['tempID', 'permID', 'mutType', 'location', 's', 'h', 'initial_subpop', \n",
    "                                  'origin_gen','fix_gen'])\n",
    "\n",
    "        #Keep only beneficial mutations\n",
    "        sweeps = fixed[fixed.mutType=='m0']\n",
    "        #Keep only fixations that occured up to 0.5Ne generations ago\n",
    "        sweeps = sweeps[sweeps.fix_gen >= (17*7000)-(0.5*7000)]\n",
    "        #Reset index for sweeps df\n",
    "        sweeps = sweeps.reset_index(drop=True)\n",
    "        #Set window start and end for sweep detection\n",
    "        sweeps['win_start'] = sweeps.location - (winSize/2)\n",
    "        #If start is less than 0, set to 0\n",
    "        sweeps['win_start'] = np.where(sweeps.win_start < 0, 0, sweeps.win_start)\n",
    "        sweeps['win_end'] = sweeps.location + (winSize/2)\n",
    "        sweeps['win_end'] = np.where(sweeps.win_end > regionLen, regionLen, sweeps.win_end)\n",
    "        #Create list of windows based on window size\n",
    "        wins = [i for i in range(1, regionLen + winSize, winSize)]\n",
    "        #Bin snps by window\n",
    "        res['genomic_window'] = pd.cut(res['snp_position'], wins, labels=wins[:-1])\n",
    "        #Create binary column for whether a sweep falls within range of this snp\n",
    "        res['sweep'] = 0\n",
    "        #Loop through sweeps, identifying snps that are within range of the sweep, and setting binary to 1\n",
    "        for i in range(0, len(sweeps)):\n",
    "            res['sweep'] = np.where((res.snp_position >= sweeps.win_start[i]) & \n",
    "                                        (res.snp_position <= sweeps.win_end[i]), 1, res.sweep)\n",
    "\n",
    "        #Group by windows, get max H12 values, and whether sweeps exist, and whether thresholds are passed\n",
    "        l1 = list(res.groupby('genomic_window')['H12'].max())    \n",
    "        l2 = list(res.groupby('genomic_window')['sweep'].sum())\n",
    "        #Create df\n",
    "        df = pd.DataFrame([l2,l1]).T\n",
    "        df.columns = ['sweep', 'H12']\n",
    "\n",
    "        #Set threshold for the 95% tail and null threshold\n",
    "        outlier_threshold = df['H12'].quantile(.95)\n",
    "        df['95th_quantile'] = np.where(df['H12']>=outlier_threshold, 1, 0)\n",
    "        df['null_threshold'] = np.where(df['H12']>=null_threshold, 1, 0)\n",
    "\n",
    "        #Set binary columns to 1 if theyre greater than 1 (as sum was used)\n",
    "        df['sweep'] = np.where(df['sweep'] > 1, 1, df['sweep'])\n",
    "\n",
    "        #START ADJACENT WINDOWS METHOD FOR OUTLIER METHOD\n",
    "        t = outlier_threshold\n",
    "        #Set choices and conditions, then use np.select to create new column\n",
    "        choices = ['FN','TP','FP','TN']\n",
    "        conditions = [(df[col1]<t) & (df[col2]==1), \n",
    "                     (df[col1]>=t) & (df[col2]==1),\n",
    "                     (df[col1]>=t) & (df[col2]==0),\n",
    "                     (df[col1]<t) & (df[col2]==0)]\n",
    "\n",
    "        df['outlier_outcome'] = np.select(conditions, choices, default=np.nan)\n",
    "        lst = list(df.outlier_outcome)\n",
    "        #Create columns for the final outcome (which will be adjusted through iterative process)\n",
    "        df['final_outlier_outcome'] = df.outlier_outcome\n",
    "        #Create columns shifted one forward and back\n",
    "        df[\"next_outlier_outcome\"] = df.outlier_outcome.shift(-1) \n",
    "        df[\"prior_outlier_outcome\"] = df.outlier_outcome.shift(1)\n",
    "        #While loop keeps until there are no instances where a true positive is next to a false positive\n",
    "        while(len(df[(df.next_outlier_outcome.eq(\"TP\") & df.final_outlier_outcome.eq(\"FP\")) |\n",
    "           (df.prior_outlier_outcome.eq(\"TP\") & df.final_outlier_outcome.eq(\"FP\"))]) > 0):\n",
    "            #If the next window (either before or after) is a TP, set to TP\n",
    "            df['final_outlier_outcome'] = np.where(df.next_outlier_outcome.eq(\"TP\") & \n",
    "                                                   df.outlier_outcome.eq(\"FP\") & (df[col1]>=t), 'TP', \n",
    "                                           df.final_outlier_outcome)\n",
    "            df['final_outlier_outcome'] = np.where(df.prior_outlier_outcome.eq(\"TP\") & \n",
    "                                                   df.outlier_outcome.eq(\"FP\") & (df[col1]>=t), 'TP', \n",
    "                                           df.final_outlier_outcome)\n",
    "            #Adjust shifted columns to account for changes\n",
    "            df[\"next_outlier_outcome\"] = df.final_outlier_outcome.shift(-1)\n",
    "            df[\"prior_outlier_outcome\"] = df.final_outlier_outcome.shift(1)\n",
    "\n",
    "        #START ADJACENT WINDOWS METHOD FOR nULL METHOD\n",
    "        #Repeat steps as above but for the null threshold\n",
    "        t = null_threshold\n",
    "        choices = ['FN','TP','FP','TN']\n",
    "        conditions = [(df[col1]<t) & (df[col2]==1), \n",
    "                     (df[col1]>=t) & (df[col2]==1),\n",
    "                     (df[col1]>=t) & (df[col2]==0),\n",
    "                     (df[col1]<t) & (df[col2]==0)]\n",
    "\n",
    "        df['null_outcome'] = np.select(conditions, choices, default=np.nan)\n",
    "\n",
    "        lst = list(df.null_outcome)\n",
    "\n",
    "        df['final_null_outcome'] = df.null_outcome\n",
    "        df[\"next_null_outcome\"] = df.null_outcome.shift(-1) \n",
    "        df[\"prior_null_outcome\"] = df.null_outcome.shift(1)\n",
    "\n",
    "        while(len(df[(df.next_null_outcome.eq(\"TP\") & df.final_null_outcome.eq(\"FP\")) |\n",
    "           (df.prior_null_outcome.eq(\"TP\") & df.final_null_outcome.eq(\"FP\"))]) > 0):\n",
    "            df['final_null_outcome'] = np.where(df.next_null_outcome.eq(\"TP\") & \n",
    "                                                   df.null_outcome.eq(\"FP\") & (df[col1]>=t), 'TP', \n",
    "                                           df.final_null_outcome)\n",
    "            df['final_null_outcome'] = np.where(df.prior_null_outcome.eq(\"TP\") & \n",
    "                                                   df.null_outcome.eq(\"FP\") & (df[col1]>=t), 'TP', \n",
    "                                           df.final_null_outcome)\n",
    "            df[\"next_null_outcome\"] = df.final_null_outcome.shift(-1)\n",
    "            df[\"prior_null_outcome\"] = df.final_null_outcome.shift(1)\n",
    "\n",
    "\n",
    "\n",
    "        #Count number of TPs etc and append to lists\n",
    "        TP = len(df[(df.final_outlier_outcome=='TP')])\n",
    "        TN = len(df[(df.final_outlier_outcome=='TN')])\n",
    "        FP = len(df[(df.final_outlier_outcome=='FP')])\n",
    "        FN = len(df[(df.final_outlier_outcome=='FN')])\n",
    "        #Get number of windows in the tail\n",
    "        tailWins = df['95th_quantile'].value_counts()[1]\n",
    "        #Get count of number of sweeps\n",
    "        totalSweeps = df['sweep'].value_counts()[1]\n",
    "        #Append to list\n",
    "        tail.append([TP, TN, FP, FN, tailWins, totalSweeps])\n",
    "        #Repeat for null analysis\n",
    "        TP = len(df[(df.final_null_outcome=='TP')])\n",
    "        TN = len(df[(df.final_null_outcome=='TN')])\n",
    "        FP = len(df[(df.final_null_outcome=='FP')])\n",
    "        FN = len(df[(df.final_null_outcome=='FN')])\n",
    "        positiveWins = df['null_threshold'].value_counts()[1]\n",
    "\n",
    "        null.append([TP, TN, FP, FN, positiveWins, totalSweeps])\n",
    "\n",
    "    except Exception:\n",
    "        pass\n",
    "#Create dataframes of sums across all replicates\n",
    "tdf = pd.DataFrame(tail, columns=['TP','TN','FP','FN', 'windows_in_tail', 'totalSweeps'])\n",
    "ndf = pd.DataFrame(null, columns=['TP','TN','FP','FN', 'positive_windows', 'totalSweeps'])\n",
    "tdf['FN%'] = (tdf['FN']/tdf['totalSweeps'])*100\n",
    "tdf['TP%'] = (tdf['TP']/tdf['windows_in_tail'])*100\n",
    "tdf['FP%'] = (tdf['FP']/tdf['windows_in_tail'])*100\n",
    "tdf.replace([np.inf, -np.inf], np.nan)\n",
    "tdf.dropna(inplace=True)\n",
    "\n",
    "ndf['FN%'] = (ndf['FN']/ndf['totalSweeps'])*100          \n",
    "ndf['TP%'] = (ndf['TP']/ndf['positive_windows'])*100\n",
    "ndf['FP%'] = (ndf['FP']/ndf['positive_windows'])*100\n",
    "ndf.replace([np.inf, -np.inf], np.nan)\n",
    "ndf.dropna(inplace=True)\n",
    "#Append to results list\n",
    "results.append([demog, N,tdf['TP%'].mean(),tdf['FP%'].mean(),tdf['FN%'].mean(),\n",
    "                ndf['TP%'].mean(),ndf['FP%'].mean(),ndf['FN%'].mean()])\n",
    "#Convert to df and concatenate with results df\n",
    "rdf = pd.DataFrame(results, columns=['demog','2Nes','TP_tail','FP_tail','FN_tail',\n",
    "                                                     'TP_null','FP_null','FN_null'])\n",
    "#Output to file    \n",
    "rdf.to_csv(outFile, sep='\\t', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
